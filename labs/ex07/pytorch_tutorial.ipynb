{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available!\n"
     ]
    }
   ],
   "source": [
    "# Check that MPS is available\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "else:\n",
    "    print(\"MPS is available!\")\n",
    "    mps_device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.2952, 0.0262],\n",
      "        [0.4571, 0.4476]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create tensor from data\n",
    "data = [[1, 2],[3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "\n",
    "# create tensor form numpy array\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "\n",
    "# retain properties from the original tensor\n",
    "x_ones = torch.ones_like(x_data)\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "# override dtype\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float)\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([2, 3])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: mps:0\n"
     ]
    }
   ],
   "source": [
    "#determine dimensionality of tensor\n",
    "shape = (2,3)\n",
    "rand_tensor = torch.rand(shape, device=mps_device)\n",
    "print(f\"Shape of tensor: {rand_tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {rand_tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {rand_tensor.device}\")\n",
    "\n",
    "#print(torch.backends.mps.is_available())\n",
    "#rand_tensor.to('cpu')\n",
    "#print(f\"Device tensor is stored on: {rand_tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, mps:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/johannes/Desktop/ML/ML_course/labs/ex07/pytorch_tutorial.ipynb Zelle 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/johannes/Desktop/ML/ML_course/labs/ex07/pytorch_tutorial.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m test_ones \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand_like(rand_tensor, device\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/johannes/Desktop/ML/ML_course/labs/ex07/pytorch_tutorial.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m C \u001b[39m=\u001b[39m test_ones \u001b[39m*\u001b[39;49m rand_tensor\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/johannes/Desktop/ML/ML_course/labs/ex07/pytorch_tutorial.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(C)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/johannes/Desktop/ML/ML_course/labs/ex07/pytorch_tutorial.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDevice tensor is stored on: \u001b[39m\u001b[39m{\u001b[39;00mtest_ones\u001b[39m.\u001b[39mdevice\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, mps:0 and cpu!"
     ]
    }
   ],
   "source": [
    "test_ones = torch.rand_like(rand_tensor, device='cpu')\n",
    "C = test_ones * rand_tensor\n",
    "\n",
    "print(C)\n",
    "\n",
    "print(f\"Device tensor is stored on: {test_ones.device}\")\n",
    "print(test_ones)\n",
    "test_ones.to(mps_device)\n",
    "print(test_ones)\n",
    "print(f\"Device tensor is stored on: {test_ones.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0264, 0.2462, 0.5204],\n",
      "        [0.0393, 0.1501, 0.0578]], device='mps:0')\n",
      "tensor([[0.0264, 0.2462, 0.5204],\n",
      "        [0.0393, 0.1501, 0.0578]], device='mps:0')\n",
      "tensor([[0.5019, 0.1226],\n",
      "        [0.2258, 0.0799]], device='mps:0')\n",
      "tensor([[0.5019, 0.1226],\n",
      "        [0.2258, 0.0799]], device='mps:0')\n",
      "tensor([[1.5019, 1.1226],\n",
      "        [1.2258, 1.0799]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "#concatinate tensors\n",
    "t1 = torch.cat([rand_tensor, rand_tensor, rand_tensor], dim=1)\n",
    "\n",
    "#element wise product\n",
    "t2 = rand_tensor.mul(rand_tensor)\n",
    "t3 = rand_tensor * rand_tensor\n",
    "print(t2)\n",
    "print(t3)\n",
    "\n",
    "#matrix multiplication\n",
    "t4 = rand_tensor.matmul(t2.T)\n",
    "t5 = rand_tensor @ t2.T\n",
    "print(t4)\n",
    "print(t5)\n",
    "\n",
    "#inplace operations\n",
    "t5.add_(1)\n",
    "print(t5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In-place operations save some memory, but can be problematic when computing derivatives because of an immediate loss of history. Hence, their use is discouraged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bridge to Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "other way around numpy to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)\n",
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /Users/johannes/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:08<00:00, 5.64MB/s]\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "data = torch.rand(1, 3, 64, 64)\n",
    "labels = torch.rand(1, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we run the input data through the model through each of its layers to make a prediction. This is the forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model(data) # forward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the model’s prediction and the corresponding label to calculate the error (loss). The next step is to backpropagate this error through the network. Backward propagation is kicked off when we call .backward() on the error tensor. Autograd then calculates and stores the gradients for each model parameter in the parameter’s .grad attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = (prediction - labels).sum()\n",
    "loss.backward() # backward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load an optimizer, in this case SGD with a learning rate of 0.01 and momentum of 0.9. We register all the parameters of the model in the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
    "optim.step() #gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Differentiation in AutoGrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "requires_grad signalizes that of every operation should be kept track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([2., 3.], requires_grad=True)\n",
    "b = torch.tensor([6., 4.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create another tensor\n",
    "$$\n",
    "    Q = 3a^3 - b^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = 3*a**3 - b**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s assume a and b to be parameters of an NN, and Q to be the error. In NN training, we want gradients of the error w.r.t. parameters, i.e.\n",
    "$$\n",
    "    \\frac{\\partial Q}{\\partial a} = 9 a^2\n",
    "$$\n",
    "$$\n",
    "    \\frac{\\partial Q}{\\partial b} = -2b\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we call .backward() on Q, autograd calculates these gradients and stores them in the respective tensors’ .grad attribute.\n",
    "\n",
    "We need to explicitly pass a gradient argument in Q.backward() because it is a vector. gradient is a tensor of the same shape as Q, and it represents the gradient of Q w.r.t. itself, i.e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True])\n",
      "tensor([True, True])\n"
     ]
    }
   ],
   "source": [
    "Q.backward(gradient=torch.tensor([1., 1.]))\n",
    "# check if collected gradients are correct\n",
    "print(9*a**2 == a.grad)\n",
    "print(-2*b == b.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 50, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(50, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super(Net, self).__init__() # same as super().__init__() -> allows to access methods of parent class\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(3, 50, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(50, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters are 10: 5 weights and 5 bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[[[-6.5615e-02, -1.0326e-02,  5.5221e-02, -2.9643e-02,  3.2259e-02],\n",
      "          [-6.7822e-03, -8.0203e-02,  5.9750e-02,  2.2924e-02,  1.2281e-02],\n",
      "          [-7.4020e-03, -9.1612e-02, -9.4269e-03, -7.7228e-02, -7.7851e-02],\n",
      "          [-5.5704e-02, -4.5303e-02, -2.1047e-02,  5.3509e-02,  6.2458e-02],\n",
      "          [-7.9431e-02, -1.0128e-01, -6.5948e-02, -1.1138e-01, -1.0081e-01]],\n",
      "\n",
      "         [[ 2.5288e-02, -6.1744e-02, -1.0713e-01,  5.2738e-02,  1.1016e-02],\n",
      "          [ 7.8119e-02,  8.2717e-02,  6.4527e-02,  1.1266e-01,  9.2925e-02],\n",
      "          [ 8.4544e-02,  4.1511e-02, -4.3447e-02,  1.1535e-01,  1.1394e-01],\n",
      "          [ 6.2832e-02, -5.8643e-02,  9.6707e-02,  1.0454e-01,  2.9112e-02],\n",
      "          [ 7.5918e-02,  1.4665e-02,  3.4601e-02,  2.7798e-02,  9.1383e-02]],\n",
      "\n",
      "         [[ 7.9590e-02, -2.6814e-02, -4.0847e-02,  1.3517e-02,  3.5159e-02],\n",
      "          [-1.4380e-02,  1.2375e-02,  6.6631e-02, -4.4050e-02,  3.7586e-02],\n",
      "          [ 6.3945e-02, -1.0653e-01, -9.2103e-02, -6.7523e-02, -1.1211e-01],\n",
      "          [ 1.8244e-02,  5.2380e-02,  5.8034e-02, -3.2854e-02, -2.8160e-02],\n",
      "          [ 1.0960e-01, -7.6354e-02, -5.2631e-02, -1.0571e-01,  4.7626e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0898e-02, -9.6395e-02,  4.7943e-03,  1.0865e-01,  6.5932e-02],\n",
      "          [ 6.4998e-02,  5.8829e-02,  4.7834e-03,  4.1141e-02,  5.1587e-02],\n",
      "          [ 1.1546e-01, -2.7796e-02,  8.1246e-02, -8.0554e-02, -1.0841e-02],\n",
      "          [ 1.0118e-01, -9.6556e-02, -5.9617e-02, -1.2965e-02, -6.6284e-02],\n",
      "          [-2.2899e-02, -5.1694e-03,  6.7215e-02,  1.1462e-01,  8.6076e-02]],\n",
      "\n",
      "         [[-6.8357e-02, -8.4787e-02, -2.8022e-02,  7.8805e-02, -6.3359e-02],\n",
      "          [-1.1177e-02,  2.4228e-02,  2.7486e-02, -1.9718e-02, -2.9491e-02],\n",
      "          [-6.0377e-02, -7.4036e-03, -4.5125e-02, -1.0366e-01, -7.8854e-02],\n",
      "          [-9.7970e-02,  8.0221e-03,  7.4647e-03,  8.8648e-02,  6.7706e-02],\n",
      "          [-1.0990e-01,  6.7029e-02, -2.1745e-04, -6.9663e-02,  7.2081e-02]],\n",
      "\n",
      "         [[ 1.0508e-01,  9.5172e-02,  2.5965e-02,  9.7647e-02,  1.2478e-02],\n",
      "          [-7.0511e-02,  9.1990e-02, -1.9797e-03, -8.8019e-02,  2.2436e-02],\n",
      "          [ 1.9075e-02,  1.0048e-01,  1.0325e-01, -9.9077e-02, -6.5050e-02],\n",
      "          [-5.6085e-02,  8.2122e-02, -6.7229e-02, -9.2288e-02,  1.9450e-02],\n",
      "          [ 7.3493e-03, -5.0828e-02,  7.1939e-02,  7.9972e-02, -4.5031e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.0070e-03,  4.9278e-02, -4.1534e-02,  6.5794e-02,  6.8673e-02],\n",
      "          [-6.6482e-02,  2.1181e-02,  5.4294e-03,  7.0062e-02,  9.3565e-02],\n",
      "          [ 8.5341e-02, -3.2164e-02, -1.3627e-02,  8.0736e-02, -9.6608e-02],\n",
      "          [ 7.3370e-02, -8.8441e-02,  4.8014e-02,  2.1668e-02,  7.5193e-02],\n",
      "          [-6.6779e-04, -1.1226e-01, -8.3623e-02, -7.6449e-02, -5.0226e-02]],\n",
      "\n",
      "         [[-8.0226e-02,  8.7940e-02,  5.7143e-02,  5.1691e-02,  2.3716e-02],\n",
      "          [ 1.0155e-01, -1.0184e-01, -2.8457e-02, -1.2048e-02, -1.0609e-01],\n",
      "          [-9.3455e-02, -1.0979e-01,  6.1240e-02,  5.7341e-02,  6.7397e-02],\n",
      "          [ 2.7020e-02,  5.1139e-02,  1.2148e-02,  8.6901e-02, -1.0421e-01],\n",
      "          [-3.7140e-02,  1.6298e-02, -7.2789e-02, -5.7748e-02,  6.4472e-02]],\n",
      "\n",
      "         [[ 6.8511e-02,  1.7660e-02,  4.5048e-02, -7.9854e-02,  8.8581e-02],\n",
      "          [-4.8328e-02,  2.9153e-04,  1.0909e-01,  3.6360e-02, -7.1117e-02],\n",
      "          [-7.0673e-02, -2.2703e-02, -9.1589e-02,  8.8634e-02, -6.8762e-02],\n",
      "          [-1.1022e-01,  1.8628e-02,  7.5260e-02, -1.0628e-01, -9.2719e-02],\n",
      "          [-1.7688e-02,  3.4437e-02, -2.6392e-02, -9.5869e-02,  5.1939e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.2367e-02, -2.2873e-02, -7.9810e-02,  2.8674e-02, -3.0465e-02],\n",
      "          [-2.4300e-02, -4.3659e-02, -1.1066e-02, -3.6598e-02, -6.8680e-02],\n",
      "          [ 6.5207e-05,  1.1069e-02,  1.1249e-01, -9.2776e-02,  7.7179e-02],\n",
      "          [ 2.0498e-02,  1.3344e-02, -6.0424e-02, -7.3847e-02, -9.1628e-02],\n",
      "          [-1.1463e-01, -1.2238e-02,  1.0841e-01, -1.0188e-01,  8.3986e-02]],\n",
      "\n",
      "         [[ 6.3577e-02,  3.0428e-02, -4.7484e-02, -1.8358e-02, -6.6663e-03],\n",
      "          [-9.4000e-02, -8.4814e-02, -4.5747e-02, -9.6704e-02,  6.3529e-02],\n",
      "          [ 2.5428e-02, -3.5464e-02, -7.7264e-03,  6.6096e-02,  2.3390e-02],\n",
      "          [-3.8503e-02, -6.7951e-02, -1.0306e-01, -3.1972e-02,  7.3605e-02],\n",
      "          [-8.5610e-02, -2.1110e-02,  1.0285e-01, -2.8358e-02, -8.0822e-02]],\n",
      "\n",
      "         [[ 6.2024e-02, -3.9520e-02, -9.1905e-02, -8.3643e-02, -2.5477e-02],\n",
      "          [ 1.0271e-01,  2.1852e-02,  1.1271e-01, -8.4286e-02, -7.6310e-02],\n",
      "          [ 7.0153e-02,  7.5104e-02, -7.6748e-02,  3.7618e-02,  1.1029e-01],\n",
      "          [ 6.4201e-02,  8.0509e-02,  7.5234e-02,  4.8236e-02,  7.5381e-03],\n",
      "          [ 7.3882e-02,  1.1440e-01, -2.3661e-02,  1.9403e-02, -8.8848e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1205e-01, -7.1671e-02,  6.5766e-02, -5.1006e-02,  4.1939e-02],\n",
      "          [ 8.4690e-02,  6.4229e-02,  1.4695e-03,  3.0799e-02,  8.4824e-02],\n",
      "          [-9.8846e-02, -3.3543e-02, -1.0091e-01,  2.1376e-02,  9.6248e-02],\n",
      "          [-4.8072e-02, -9.6682e-02, -1.9106e-02, -5.0695e-02, -2.6815e-02],\n",
      "          [-8.1080e-02, -7.6108e-02,  4.8873e-02,  6.5431e-02,  2.5574e-03]],\n",
      "\n",
      "         [[-4.4224e-02, -4.3980e-02,  6.4499e-02,  4.6056e-03,  4.2783e-02],\n",
      "          [-1.8997e-02, -9.4912e-02,  7.3195e-02,  9.6288e-02, -7.5029e-02],\n",
      "          [-6.0736e-02,  5.2004e-02,  7.8546e-02,  6.0800e-02, -1.1092e-01],\n",
      "          [-8.5934e-02,  6.9555e-02, -9.2704e-02,  7.7364e-02,  7.8109e-02],\n",
      "          [-7.0178e-02, -2.5448e-02, -4.9342e-04, -6.7425e-02,  7.8626e-02]],\n",
      "\n",
      "         [[-6.2863e-02,  4.6358e-02,  7.4609e-02,  1.1033e-01, -8.9201e-02],\n",
      "          [ 9.4154e-02,  3.5562e-02, -6.3839e-02, -1.2542e-02,  2.9571e-02],\n",
      "          [-2.2440e-02, -7.3028e-02, -2.5051e-02,  1.6148e-02, -9.1558e-02],\n",
      "          [ 2.6346e-02,  2.3385e-02, -2.0492e-02,  3.9906e-02, -5.6926e-02],\n",
      "          [ 6.4185e-02, -1.1311e-01, -5.6232e-02,  2.7011e-02, -6.9643e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1012e-02, -1.0013e-01,  1.7558e-03,  6.5272e-02,  7.5386e-02],\n",
      "          [-7.7499e-02, -1.7573e-02,  9.3354e-02, -8.9144e-02,  1.0336e-01],\n",
      "          [-1.0428e-02, -6.4775e-02, -1.0793e-01,  1.0001e-01,  1.0188e-01],\n",
      "          [ 8.8290e-02,  5.2360e-02,  3.8636e-02,  4.5128e-02,  3.4928e-02],\n",
      "          [-1.0955e-01,  1.1436e-01, -9.0392e-02, -5.5868e-02,  2.3563e-02]],\n",
      "\n",
      "         [[-4.9085e-02,  2.3100e-02, -1.7221e-02, -6.0221e-02, -8.0067e-02],\n",
      "          [-2.9429e-02,  7.1391e-02, -7.4934e-02, -1.1025e-01,  5.0128e-02],\n",
      "          [-4.2473e-02, -5.9076e-03, -6.8939e-02,  7.1956e-02,  1.3710e-03],\n",
      "          [ 1.4551e-02,  6.1944e-02,  6.4192e-02,  4.1320e-02, -3.0070e-02],\n",
      "          [ 9.6537e-05,  5.9357e-02,  5.7416e-03, -2.9764e-02,  3.4630e-02]],\n",
      "\n",
      "         [[-1.0050e-02, -5.6480e-04,  2.7728e-02,  8.6855e-02, -2.3522e-02],\n",
      "          [-8.9494e-02,  6.5310e-02, -1.0913e-01,  2.8115e-03,  5.4431e-02],\n",
      "          [ 1.1527e-01,  3.7345e-02, -9.9042e-02,  1.0531e-01,  1.1135e-01],\n",
      "          [-7.0277e-02, -1.0921e-01, -6.3657e-02, -4.7178e-02, -6.7059e-02],\n",
      "          [ 5.8435e-02,  9.5870e-02,  2.8170e-03,  2.4555e-02, -8.7953e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.7067e-02, -4.3424e-02, -6.7069e-02, -9.5459e-02,  9.6240e-02],\n",
      "          [-4.0162e-02, -1.4847e-03, -3.7758e-02, -3.9837e-02, -7.6563e-02],\n",
      "          [ 8.9060e-02, -1.1078e-01,  5.4742e-03, -7.4569e-02, -1.5875e-02],\n",
      "          [-5.0918e-02,  4.4132e-02, -5.9656e-02,  8.7366e-02,  9.8983e-02],\n",
      "          [-5.2860e-02,  9.7970e-02, -3.1831e-02, -4.3814e-02,  5.6103e-02]],\n",
      "\n",
      "         [[ 4.9044e-02, -3.5977e-02, -1.5055e-02,  3.4570e-04, -7.6692e-02],\n",
      "          [ 3.1051e-02,  6.9044e-02, -1.0691e-01, -5.2407e-02, -3.8172e-02],\n",
      "          [-4.7533e-02, -7.1152e-02,  3.2030e-02,  2.6945e-02, -1.7855e-02],\n",
      "          [-6.6300e-02, -5.2023e-02, -9.7392e-02,  1.3091e-02,  6.9647e-03],\n",
      "          [-9.4378e-02, -4.7574e-02, -2.8438e-03, -9.1860e-02, -6.9300e-02]],\n",
      "\n",
      "         [[-2.4862e-02,  9.0431e-04,  1.0758e-01,  2.8548e-02,  6.8854e-02],\n",
      "          [ 7.5099e-02, -5.8805e-02, -2.5351e-02, -9.4088e-02, -6.3165e-03],\n",
      "          [-1.0380e-01, -9.5204e-02,  1.1098e-01,  5.9717e-02,  3.7772e-03],\n",
      "          [ 3.0596e-02, -6.5775e-02, -7.4331e-03,  9.3197e-02, -6.3434e-02],\n",
      "          [-2.9749e-02, -5.1029e-02,  8.2244e-02,  4.4198e-02, -3.4532e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1123e-01, -6.1983e-02, -1.1325e-01, -1.0655e-02, -1.0436e-01],\n",
      "          [-5.6086e-02, -2.5578e-03, -5.6355e-02,  8.9670e-02, -4.4354e-02],\n",
      "          [-7.5889e-02,  7.6405e-02, -4.0316e-02, -9.4586e-02,  7.2435e-02],\n",
      "          [ 4.5119e-02,  5.6631e-02,  2.0785e-03,  6.7428e-02, -3.3270e-03],\n",
      "          [-6.1339e-02,  1.0168e-01,  8.0942e-02, -6.6552e-02, -1.8522e-02]],\n",
      "\n",
      "         [[-6.9226e-02, -2.1292e-02,  7.3967e-02, -6.8399e-04,  4.6288e-02],\n",
      "          [ 1.0575e-01,  5.6792e-02, -8.5157e-02, -9.0662e-02,  1.5801e-02],\n",
      "          [ 1.1109e-01, -1.1044e-01, -6.3733e-03,  2.2196e-02,  4.7911e-02],\n",
      "          [ 2.2609e-02, -1.5301e-02,  5.2904e-02,  6.4227e-02, -4.5233e-02],\n",
      "          [ 9.6188e-02, -1.0070e-01, -1.9730e-02, -4.5060e-02, -7.6833e-02]],\n",
      "\n",
      "         [[ 8.7099e-02, -8.6051e-02, -2.9256e-02, -1.8049e-03,  9.7458e-02],\n",
      "          [-1.7609e-02,  5.0145e-02,  4.6143e-02, -3.9938e-02, -8.5314e-02],\n",
      "          [ 5.4370e-02,  5.0784e-02,  5.9929e-02, -7.2558e-02, -6.0843e-02],\n",
      "          [ 8.2885e-02,  4.6098e-02,  3.1482e-02,  1.0557e-01, -1.1480e-01],\n",
      "          [ 7.6608e-02,  3.0906e-02,  1.0912e-02,  2.4488e-02, -1.1449e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.0045e-02,  5.6645e-02, -5.0781e-02,  8.6965e-02,  8.3051e-03],\n",
      "          [-8.5331e-02,  8.9419e-02,  2.5681e-02, -5.4246e-02, -1.5776e-02],\n",
      "          [ 6.2626e-02,  6.4345e-02, -5.5580e-02,  2.3730e-03, -2.1404e-02],\n",
      "          [ 6.8381e-02, -5.1403e-02, -3.3440e-02, -3.8169e-02,  1.1446e-01],\n",
      "          [ 8.9214e-02,  1.0478e-02, -1.0127e-01,  1.0043e-01, -3.7972e-02]],\n",
      "\n",
      "         [[-4.9434e-02, -1.0005e-01, -9.4356e-03,  9.9346e-03,  5.1049e-02],\n",
      "          [-9.6044e-02, -5.5746e-02,  6.5280e-02,  3.0082e-02,  7.8845e-02],\n",
      "          [-2.2854e-03, -1.6048e-02,  1.2759e-03,  2.3959e-02,  4.4522e-02],\n",
      "          [ 6.6270e-02,  1.9670e-02,  9.6166e-02,  1.0135e-01,  8.2639e-02],\n",
      "          [ 9.2568e-02, -1.3724e-02, -1.0374e-02, -6.0752e-02, -9.4124e-02]],\n",
      "\n",
      "         [[-1.6176e-02, -8.9004e-02,  3.0715e-02, -6.7820e-02, -1.1236e-02],\n",
      "          [-6.9002e-02,  7.3145e-02,  7.2931e-02,  5.3772e-02,  5.0607e-03],\n",
      "          [-3.5703e-02, -7.1424e-02, -4.7108e-03,  8.2596e-02,  3.8824e-02],\n",
      "          [-7.7831e-02, -7.4624e-02,  2.5803e-02,  3.7367e-02,  3.2240e-02],\n",
      "          [ 8.4102e-02,  1.5802e-02, -1.0705e-01, -7.5777e-02,  9.4738e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.8735e-02, -2.4583e-02,  2.9368e-02,  5.0015e-02, -3.2932e-02],\n",
      "          [ 7.8414e-02, -6.0344e-02,  4.9324e-03,  1.0855e-01,  4.0020e-02],\n",
      "          [ 3.5530e-02,  3.2715e-02, -8.6805e-02, -8.3720e-02, -1.1286e-01],\n",
      "          [ 3.7113e-02, -6.9796e-02, -2.7279e-02,  2.3861e-02, -1.0608e-01],\n",
      "          [-1.0955e-01, -5.8261e-02,  7.6971e-02,  4.5724e-02, -1.2711e-02]],\n",
      "\n",
      "         [[ 4.2088e-02,  8.8097e-02, -6.8097e-02,  1.0965e-01, -1.1341e-01],\n",
      "          [ 8.9510e-02,  1.0707e-01, -3.2083e-02, -1.8077e-02,  8.5409e-02],\n",
      "          [-7.3516e-02, -1.0824e-01,  9.6905e-02,  7.2480e-02,  1.1265e-01],\n",
      "          [ 9.2598e-02,  9.3021e-02, -2.3467e-02, -8.2898e-02, -8.7149e-03],\n",
      "          [ 8.2671e-02,  6.3822e-02, -2.5385e-02,  9.5510e-02, -5.8119e-02]],\n",
      "\n",
      "         [[-3.2882e-02, -1.8439e-02,  6.9166e-02,  5.8365e-02, -6.7653e-02],\n",
      "          [-4.6026e-02, -5.9860e-02,  9.8551e-02, -7.1586e-02, -1.1262e-02],\n",
      "          [ 9.3280e-02,  8.7646e-02,  8.4449e-02,  1.1343e-01,  1.2222e-02],\n",
      "          [-1.0816e-01, -5.3294e-02,  4.3733e-02,  9.4617e-02, -4.3043e-02],\n",
      "          [ 1.0093e-01, -5.3757e-02,  1.0320e-01,  6.3258e-02,  1.7312e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0406e-02, -9.8796e-03,  1.0325e-02,  6.6880e-02, -3.8965e-02],\n",
      "          [-5.3053e-02, -3.0305e-02,  7.3589e-02,  3.0378e-02, -5.0331e-02],\n",
      "          [-3.3104e-02, -7.6788e-02,  9.4022e-02,  1.8418e-02, -1.9085e-02],\n",
      "          [ 1.0296e-01,  5.9055e-02, -2.8625e-02,  1.0953e-01, -1.5541e-02],\n",
      "          [ 7.2171e-02, -1.1191e-01,  5.8532e-02,  6.5456e-02,  6.0381e-02]],\n",
      "\n",
      "         [[-4.9870e-02,  9.6878e-02,  1.1013e-01,  6.1797e-02,  5.8417e-02],\n",
      "          [ 5.4406e-02, -6.8439e-02,  7.3412e-02, -3.2865e-02, -5.5271e-02],\n",
      "          [-3.4639e-02, -9.3595e-02,  3.9940e-02,  9.4033e-02,  1.1171e-01],\n",
      "          [ 7.3206e-02, -5.9009e-03, -5.5224e-02,  6.0303e-02,  1.0081e-01],\n",
      "          [-1.0273e-02,  7.7239e-02,  9.7011e-02, -1.0461e-01,  6.7189e-02]],\n",
      "\n",
      "         [[ 3.9054e-02,  5.3020e-02, -8.2907e-02, -5.7240e-02, -2.3560e-02],\n",
      "          [ 5.1650e-02, -6.2939e-02, -2.5861e-02, -1.1536e-01, -4.5962e-02],\n",
      "          [ 8.6628e-02,  7.9234e-02,  9.5928e-03,  5.2610e-02,  2.2226e-02],\n",
      "          [ 1.5343e-02, -6.8116e-03,  1.1453e-02, -5.2383e-02, -1.0733e-01],\n",
      "          [-6.3962e-02, -1.9416e-02, -1.1444e-01, -9.5340e-02, -3.6432e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0375e-02, -2.0640e-02,  2.9375e-02,  3.8079e-02, -1.1246e-02],\n",
      "          [-5.8751e-02, -6.3008e-02,  5.1157e-02, -3.7422e-02, -1.0083e-01],\n",
      "          [ 8.4324e-02,  5.6568e-02, -2.9148e-02, -5.6604e-02, -8.2665e-02],\n",
      "          [-1.0775e-01,  6.2512e-02, -8.4397e-02,  5.5381e-02, -8.3335e-03],\n",
      "          [ 1.0972e-01,  3.3035e-02, -4.1438e-02,  9.7280e-03, -4.5941e-03]],\n",
      "\n",
      "         [[ 1.3253e-02, -1.0395e-01,  5.6083e-02, -9.2712e-02, -5.3321e-02],\n",
      "          [-8.8937e-03, -5.4020e-02, -4.3040e-02,  3.8015e-02, -3.4703e-02],\n",
      "          [-2.3510e-02,  1.0846e-01,  1.7460e-02, -5.3071e-02, -9.9801e-03],\n",
      "          [ 8.7610e-02,  6.6752e-02, -5.3475e-02,  4.8135e-02, -9.9195e-03],\n",
      "          [ 1.4629e-02,  6.5178e-03,  7.5957e-02, -1.0688e-01, -5.0513e-02]],\n",
      "\n",
      "         [[-1.1016e-01, -6.5767e-03,  1.3714e-02,  1.0537e-02, -5.4357e-02],\n",
      "          [ 8.7028e-02, -8.2164e-02,  6.7481e-02,  7.0948e-02,  8.8152e-02],\n",
      "          [-8.1702e-02, -1.1454e-01, -2.5895e-03, -7.9338e-02, -3.0065e-02],\n",
      "          [ 1.0267e-01,  2.6233e-02, -1.0630e-01,  5.9023e-02, -6.5435e-04],\n",
      "          [-3.7981e-02,  8.1306e-02, -7.1362e-02, -9.9961e-02, -5.3842e-02]]]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-9.2075e-02,  3.9208e-02,  9.2205e-02,  9.8801e-02, -3.6292e-02,\n",
      "        -3.7537e-02,  6.4189e-03,  5.2476e-02,  7.9591e-02,  2.5000e-02,\n",
      "        -5.7660e-05, -9.1733e-02], requires_grad=True), Parameter containing:\n",
      "tensor([[[[-0.0077,  0.0234, -0.0568, -0.0138,  0.0449],\n",
      "          [-0.0048, -0.0529,  0.0091, -0.0279, -0.0534],\n",
      "          [ 0.0197, -0.0243, -0.0427,  0.0212,  0.0024],\n",
      "          [-0.0567,  0.0472,  0.0133,  0.0107,  0.0099],\n",
      "          [ 0.0542,  0.0387,  0.0577,  0.0052,  0.0415]],\n",
      "\n",
      "         [[-0.0496, -0.0503,  0.0063, -0.0484, -0.0535],\n",
      "          [ 0.0132,  0.0258, -0.0562, -0.0491, -0.0371],\n",
      "          [ 0.0186,  0.0505,  0.0047,  0.0379,  0.0536],\n",
      "          [-0.0445,  0.0415, -0.0105,  0.0170,  0.0276],\n",
      "          [-0.0102,  0.0552, -0.0088, -0.0471, -0.0089]],\n",
      "\n",
      "         [[-0.0186,  0.0466,  0.0128,  0.0062, -0.0054],\n",
      "          [-0.0293,  0.0180, -0.0157,  0.0425,  0.0240],\n",
      "          [-0.0302, -0.0480, -0.0261,  0.0066,  0.0008],\n",
      "          [ 0.0569,  0.0312, -0.0307, -0.0452, -0.0125],\n",
      "          [ 0.0066, -0.0010, -0.0083, -0.0477,  0.0342]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0390,  0.0121,  0.0074,  0.0445, -0.0410],\n",
      "          [-0.0228,  0.0090,  0.0252, -0.0144,  0.0025],\n",
      "          [ 0.0011, -0.0313,  0.0473, -0.0315,  0.0014],\n",
      "          [-0.0239,  0.0497,  0.0208, -0.0512, -0.0370],\n",
      "          [-0.0292, -0.0487,  0.0282, -0.0294,  0.0171]],\n",
      "\n",
      "         [[-0.0253,  0.0306,  0.0379,  0.0055, -0.0381],\n",
      "          [ 0.0161, -0.0442, -0.0129,  0.0125, -0.0053],\n",
      "          [-0.0173, -0.0466, -0.0369,  0.0036, -0.0306],\n",
      "          [-0.0191, -0.0389, -0.0110, -0.0160, -0.0575],\n",
      "          [ 0.0471, -0.0317,  0.0504,  0.0143, -0.0335]],\n",
      "\n",
      "         [[ 0.0545,  0.0540, -0.0361,  0.0482,  0.0117],\n",
      "          [ 0.0124,  0.0106, -0.0005,  0.0470,  0.0436],\n",
      "          [ 0.0005, -0.0256, -0.0333, -0.0192,  0.0161],\n",
      "          [ 0.0148,  0.0152,  0.0363, -0.0058, -0.0042],\n",
      "          [ 0.0256,  0.0026, -0.0573,  0.0564, -0.0103]]],\n",
      "\n",
      "\n",
      "        [[[-0.0077, -0.0301, -0.0347, -0.0385, -0.0148],\n",
      "          [-0.0463, -0.0566,  0.0457, -0.0334, -0.0450],\n",
      "          [ 0.0512,  0.0447, -0.0496,  0.0006, -0.0012],\n",
      "          [-0.0381, -0.0210, -0.0416,  0.0445, -0.0384],\n",
      "          [ 0.0536,  0.0258,  0.0209,  0.0153, -0.0391]],\n",
      "\n",
      "         [[ 0.0051,  0.0322,  0.0360, -0.0071,  0.0471],\n",
      "          [-0.0379, -0.0537,  0.0556, -0.0421,  0.0571],\n",
      "          [ 0.0544, -0.0054,  0.0332,  0.0509, -0.0293],\n",
      "          [ 0.0334,  0.0516,  0.0252,  0.0378, -0.0498],\n",
      "          [-0.0235, -0.0049, -0.0327, -0.0384, -0.0199]],\n",
      "\n",
      "         [[ 0.0477, -0.0407,  0.0308,  0.0327,  0.0454],\n",
      "          [ 0.0497, -0.0489,  0.0013, -0.0106,  0.0087],\n",
      "          [-0.0393, -0.0300, -0.0161, -0.0010, -0.0177],\n",
      "          [-0.0322, -0.0522, -0.0377,  0.0255,  0.0484],\n",
      "          [ 0.0374,  0.0422, -0.0440, -0.0270,  0.0191]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0529,  0.0155,  0.0345,  0.0238, -0.0282],\n",
      "          [-0.0486,  0.0215,  0.0082,  0.0160,  0.0076],\n",
      "          [-0.0119,  0.0146, -0.0216, -0.0522,  0.0417],\n",
      "          [ 0.0575,  0.0341,  0.0327,  0.0036,  0.0268],\n",
      "          [ 0.0227, -0.0009, -0.0104,  0.0115,  0.0545]],\n",
      "\n",
      "         [[ 0.0451,  0.0082,  0.0311, -0.0508, -0.0196],\n",
      "          [-0.0052,  0.0084,  0.0509,  0.0445,  0.0144],\n",
      "          [ 0.0187,  0.0387, -0.0052, -0.0055,  0.0034],\n",
      "          [-0.0101, -0.0519,  0.0506, -0.0007,  0.0423],\n",
      "          [ 0.0248,  0.0507, -0.0384, -0.0383,  0.0167]],\n",
      "\n",
      "         [[-0.0333,  0.0076, -0.0003,  0.0217,  0.0533],\n",
      "          [-0.0512, -0.0210,  0.0252, -0.0245, -0.0167],\n",
      "          [-0.0425, -0.0468,  0.0293,  0.0141,  0.0412],\n",
      "          [ 0.0017, -0.0308, -0.0556, -0.0565, -0.0223],\n",
      "          [-0.0470,  0.0315,  0.0164, -0.0383,  0.0377]]],\n",
      "\n",
      "\n",
      "        [[[-0.0302,  0.0539, -0.0463,  0.0006,  0.0273],\n",
      "          [ 0.0068, -0.0428, -0.0496, -0.0493, -0.0248],\n",
      "          [ 0.0479,  0.0326,  0.0248,  0.0136, -0.0473],\n",
      "          [ 0.0249, -0.0376, -0.0014,  0.0036, -0.0085],\n",
      "          [-0.0395,  0.0214, -0.0503,  0.0423,  0.0383]],\n",
      "\n",
      "         [[-0.0404, -0.0528,  0.0274,  0.0536,  0.0232],\n",
      "          [ 0.0480,  0.0531,  0.0055,  0.0337, -0.0011],\n",
      "          [-0.0183, -0.0476,  0.0265,  0.0567, -0.0004],\n",
      "          [ 0.0437, -0.0193,  0.0186,  0.0301, -0.0063],\n",
      "          [ 0.0175,  0.0359,  0.0383,  0.0555, -0.0166]],\n",
      "\n",
      "         [[ 0.0152,  0.0148,  0.0099,  0.0015, -0.0082],\n",
      "          [ 0.0073,  0.0399,  0.0173, -0.0009,  0.0018],\n",
      "          [-0.0042,  0.0002, -0.0121, -0.0016, -0.0110],\n",
      "          [-0.0281,  0.0410,  0.0376, -0.0123,  0.0296],\n",
      "          [-0.0424,  0.0045, -0.0481,  0.0455, -0.0042]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0093,  0.0412, -0.0316,  0.0449,  0.0058],\n",
      "          [-0.0118,  0.0052, -0.0334,  0.0217,  0.0189],\n",
      "          [ 0.0464, -0.0529, -0.0376,  0.0210, -0.0298],\n",
      "          [-0.0203,  0.0086,  0.0170, -0.0470, -0.0184],\n",
      "          [-0.0185,  0.0255, -0.0026,  0.0316,  0.0424]],\n",
      "\n",
      "         [[-0.0349,  0.0294, -0.0366, -0.0387, -0.0243],\n",
      "          [-0.0345, -0.0254,  0.0565,  0.0165,  0.0265],\n",
      "          [-0.0555,  0.0509,  0.0441,  0.0080,  0.0278],\n",
      "          [ 0.0348, -0.0288,  0.0440,  0.0319, -0.0213],\n",
      "          [ 0.0280, -0.0312,  0.0438,  0.0338,  0.0384]],\n",
      "\n",
      "         [[ 0.0369, -0.0514, -0.0196, -0.0192,  0.0448],\n",
      "          [ 0.0228,  0.0518,  0.0122, -0.0226,  0.0109],\n",
      "          [ 0.0406,  0.0337,  0.0007,  0.0374, -0.0299],\n",
      "          [ 0.0529, -0.0532,  0.0451,  0.0474,  0.0273],\n",
      "          [ 0.0466,  0.0276, -0.0516, -0.0269, -0.0132]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0469, -0.0121,  0.0514,  0.0215,  0.0217],\n",
      "          [ 0.0038,  0.0577, -0.0151,  0.0548,  0.0405],\n",
      "          [ 0.0493,  0.0271, -0.0308,  0.0095, -0.0549],\n",
      "          [ 0.0231,  0.0125, -0.0565, -0.0391,  0.0575],\n",
      "          [-0.0317, -0.0394, -0.0511, -0.0237, -0.0139]],\n",
      "\n",
      "         [[ 0.0372,  0.0115, -0.0506, -0.0540,  0.0338],\n",
      "          [ 0.0186, -0.0115,  0.0284,  0.0212, -0.0423],\n",
      "          [-0.0023,  0.0543,  0.0455,  0.0301,  0.0240],\n",
      "          [-0.0354, -0.0354,  0.0073, -0.0531,  0.0548],\n",
      "          [ 0.0158, -0.0250, -0.0266,  0.0098, -0.0085]],\n",
      "\n",
      "         [[ 0.0560,  0.0357,  0.0475, -0.0282, -0.0284],\n",
      "          [-0.0280, -0.0570,  0.0382,  0.0488, -0.0569],\n",
      "          [-0.0423,  0.0135, -0.0332,  0.0258, -0.0494],\n",
      "          [ 0.0287, -0.0497, -0.0283, -0.0010, -0.0360],\n",
      "          [ 0.0290, -0.0549,  0.0471, -0.0016, -0.0489]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0529, -0.0308, -0.0577,  0.0557, -0.0143],\n",
      "          [-0.0543,  0.0226, -0.0440, -0.0554,  0.0574],\n",
      "          [ 0.0482,  0.0195, -0.0567, -0.0297,  0.0060],\n",
      "          [-0.0338, -0.0145, -0.0080,  0.0312,  0.0021],\n",
      "          [-0.0012, -0.0177, -0.0291, -0.0412,  0.0171]],\n",
      "\n",
      "         [[-0.0351, -0.0019,  0.0156, -0.0017,  0.0308],\n",
      "          [ 0.0310, -0.0237,  0.0520, -0.0086, -0.0076],\n",
      "          [ 0.0118,  0.0399, -0.0525,  0.0456, -0.0008],\n",
      "          [-0.0509, -0.0064,  0.0167,  0.0492,  0.0376],\n",
      "          [-0.0226, -0.0062, -0.0425,  0.0137, -0.0152]],\n",
      "\n",
      "         [[-0.0347,  0.0234,  0.0214, -0.0048, -0.0264],\n",
      "          [-0.0165, -0.0289, -0.0398,  0.0568, -0.0187],\n",
      "          [-0.0144,  0.0516, -0.0562, -0.0266,  0.0492],\n",
      "          [ 0.0306, -0.0297, -0.0310,  0.0392,  0.0204],\n",
      "          [-0.0094, -0.0267,  0.0176, -0.0031, -0.0571]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0255,  0.0420, -0.0185, -0.0025,  0.0278],\n",
      "          [ 0.0043,  0.0251,  0.0471,  0.0497, -0.0480],\n",
      "          [ 0.0573, -0.0525, -0.0125,  0.0350,  0.0570],\n",
      "          [ 0.0477,  0.0329, -0.0346,  0.0574,  0.0523],\n",
      "          [ 0.0065, -0.0435,  0.0303, -0.0507,  0.0188]],\n",
      "\n",
      "         [[ 0.0468, -0.0569, -0.0358,  0.0267, -0.0380],\n",
      "          [ 0.0207, -0.0112, -0.0298, -0.0242,  0.0170],\n",
      "          [-0.0346, -0.0541, -0.0208,  0.0524, -0.0208],\n",
      "          [-0.0338, -0.0318, -0.0215,  0.0237, -0.0459],\n",
      "          [-0.0262, -0.0185, -0.0371, -0.0013, -0.0289]],\n",
      "\n",
      "         [[-0.0485,  0.0396, -0.0420,  0.0080, -0.0407],\n",
      "          [-0.0171,  0.0521,  0.0312, -0.0427, -0.0014],\n",
      "          [ 0.0109, -0.0438, -0.0435,  0.0399, -0.0570],\n",
      "          [ 0.0398, -0.0452, -0.0204,  0.0314, -0.0323],\n",
      "          [-0.0281,  0.0486, -0.0497,  0.0082,  0.0417]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0453,  0.0231,  0.0181,  0.0484,  0.0135],\n",
      "          [-0.0113, -0.0172,  0.0388, -0.0458,  0.0480],\n",
      "          [ 0.0562,  0.0043,  0.0331, -0.0506, -0.0163],\n",
      "          [ 0.0025, -0.0231,  0.0043, -0.0302, -0.0204],\n",
      "          [ 0.0207, -0.0091, -0.0420,  0.0074,  0.0135]],\n",
      "\n",
      "         [[-0.0093, -0.0070,  0.0279, -0.0377,  0.0204],\n",
      "          [ 0.0333, -0.0349,  0.0223,  0.0005, -0.0365],\n",
      "          [-0.0141,  0.0451,  0.0379,  0.0165,  0.0121],\n",
      "          [-0.0173, -0.0520, -0.0456,  0.0510, -0.0457],\n",
      "          [-0.0361,  0.0155,  0.0412, -0.0441, -0.0569]],\n",
      "\n",
      "         [[-0.0175, -0.0516,  0.0170, -0.0186, -0.0099],\n",
      "          [-0.0411, -0.0452, -0.0467, -0.0240,  0.0185],\n",
      "          [ 0.0567, -0.0533,  0.0353, -0.0506, -0.0084],\n",
      "          [-0.0135,  0.0279,  0.0020, -0.0510,  0.0286],\n",
      "          [-0.0216, -0.0452,  0.0298, -0.0096, -0.0197]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0051,  0.0166,  0.0154, -0.0295,  0.0384],\n",
      "          [-0.0144, -0.0251, -0.0270, -0.0547, -0.0191],\n",
      "          [ 0.0219,  0.0408,  0.0525,  0.0203,  0.0324],\n",
      "          [ 0.0132,  0.0360,  0.0291, -0.0468, -0.0202],\n",
      "          [ 0.0237,  0.0258, -0.0213, -0.0436, -0.0139]],\n",
      "\n",
      "         [[ 0.0549,  0.0567, -0.0349, -0.0086,  0.0168],\n",
      "          [-0.0190,  0.0159, -0.0326, -0.0473,  0.0168],\n",
      "          [-0.0209, -0.0436, -0.0172, -0.0161,  0.0127],\n",
      "          [ 0.0174,  0.0004,  0.0562, -0.0398, -0.0459],\n",
      "          [ 0.0023, -0.0355,  0.0251,  0.0092,  0.0344]],\n",
      "\n",
      "         [[ 0.0299, -0.0181, -0.0218, -0.0056, -0.0255],\n",
      "          [ 0.0180, -0.0548, -0.0519, -0.0570, -0.0467],\n",
      "          [ 0.0508,  0.0181, -0.0498, -0.0568,  0.0205],\n",
      "          [ 0.0047,  0.0324,  0.0100,  0.0375, -0.0303],\n",
      "          [ 0.0141,  0.0414,  0.0070,  0.0474, -0.0565]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0149,  0.0462, -0.0003,  0.0359, -0.0130],\n",
      "          [-0.0498, -0.0525,  0.0352,  0.0055,  0.0068],\n",
      "          [-0.0087,  0.0110,  0.0149, -0.0366, -0.0067],\n",
      "          [ 0.0435,  0.0421,  0.0014,  0.0469,  0.0437],\n",
      "          [ 0.0208, -0.0566,  0.0161, -0.0003, -0.0496]],\n",
      "\n",
      "         [[-0.0247,  0.0337,  0.0258,  0.0482, -0.0170],\n",
      "          [-0.0487, -0.0178, -0.0353,  0.0145, -0.0008],\n",
      "          [ 0.0193,  0.0245,  0.0034,  0.0447,  0.0137],\n",
      "          [ 0.0212,  0.0017, -0.0549, -0.0459,  0.0117],\n",
      "          [ 0.0403, -0.0078,  0.0056,  0.0325, -0.0337]],\n",
      "\n",
      "         [[-0.0029, -0.0525, -0.0113, -0.0304, -0.0130],\n",
      "          [ 0.0520,  0.0211,  0.0193, -0.0281, -0.0385],\n",
      "          [ 0.0429, -0.0508, -0.0134,  0.0074,  0.0135],\n",
      "          [ 0.0228,  0.0285,  0.0429, -0.0277,  0.0435],\n",
      "          [ 0.0453,  0.0194, -0.0174,  0.0361, -0.0289]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0264,  0.0346, -0.0325,  0.0142, -0.0275, -0.0197, -0.0550, -0.0399,\n",
      "        -0.0013,  0.0237,  0.0281, -0.0030,  0.0107, -0.0170, -0.0147, -0.0399],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0304, -0.0465, -0.0088,  ...,  0.0315,  0.0007, -0.0257],\n",
      "        [ 0.0096,  0.0051,  0.0284,  ..., -0.0338, -0.0058,  0.0318],\n",
      "        [-0.0037, -0.0188,  0.0193,  ..., -0.0046, -0.0156,  0.0297],\n",
      "        ...,\n",
      "        [-0.0137,  0.0006,  0.0486,  ...,  0.0265, -0.0174, -0.0311],\n",
      "        [ 0.0095,  0.0342, -0.0129,  ..., -0.0381,  0.0397,  0.0328],\n",
      "        [ 0.0354,  0.0255, -0.0214,  ..., -0.0127, -0.0475,  0.0365]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0283,  0.0379,  0.0174, -0.0366, -0.0279,  0.0188, -0.0163,  0.0141,\n",
      "        -0.0425, -0.0063, -0.0205, -0.0491,  0.0050, -0.0463, -0.0257, -0.0494,\n",
      "         0.0366,  0.0414,  0.0334, -0.0318, -0.0412,  0.0335,  0.0186,  0.0363,\n",
      "        -0.0339,  0.0381, -0.0038, -0.0092,  0.0316,  0.0349, -0.0144, -0.0045,\n",
      "        -0.0052, -0.0101, -0.0362, -0.0310,  0.0205,  0.0496,  0.0297,  0.0210,\n",
      "        -0.0285,  0.0064,  0.0037,  0.0015,  0.0499, -0.0413, -0.0117, -0.0356,\n",
      "        -0.0282, -0.0440, -0.0312,  0.0099,  0.0107,  0.0080, -0.0177,  0.0421,\n",
      "         0.0105,  0.0456, -0.0221,  0.0385, -0.0249, -0.0019, -0.0224,  0.0124,\n",
      "        -0.0027,  0.0120,  0.0084,  0.0325,  0.0235,  0.0469, -0.0214,  0.0427,\n",
      "         0.0181,  0.0195, -0.0094, -0.0397,  0.0469,  0.0485,  0.0463,  0.0281,\n",
      "        -0.0487, -0.0121, -0.0250,  0.0267, -0.0019,  0.0087, -0.0144,  0.0072,\n",
      "        -0.0424, -0.0494, -0.0230,  0.0184, -0.0011, -0.0121,  0.0143, -0.0157,\n",
      "         0.0382, -0.0439,  0.0286, -0.0492, -0.0145,  0.0088, -0.0275, -0.0122,\n",
      "         0.0101,  0.0421, -0.0182, -0.0311,  0.0387,  0.0344,  0.0308,  0.0096,\n",
      "         0.0313, -0.0481,  0.0366, -0.0051,  0.0041, -0.0097, -0.0208, -0.0463],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0072, -0.0229, -0.0433,  ...,  0.0190,  0.0520,  0.0482],\n",
      "        [-0.0636, -0.0232,  0.0482,  ...,  0.0006, -0.0688, -0.0281],\n",
      "        [-0.0296, -0.0270, -0.0461,  ..., -0.0043, -0.0885, -0.0596],\n",
      "        ...,\n",
      "        [ 0.0856, -0.0607,  0.0793,  ...,  0.0106, -0.0033, -0.0759],\n",
      "        [-0.0397, -0.0900,  0.0522,  ...,  0.0873, -0.0111, -0.0764],\n",
      "        [-0.0211,  0.0735,  0.0271,  ...,  0.0339,  0.0911, -0.0128]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0290, -0.0622,  0.0604, -0.0305, -0.0720,  0.0425,  0.0072, -0.0353,\n",
      "         0.0415,  0.0604, -0.0377,  0.0734,  0.0424, -0.0023, -0.0722,  0.0462,\n",
      "         0.0441, -0.0515, -0.0640,  0.0407, -0.0788,  0.0306, -0.0263, -0.0481,\n",
      "        -0.0246,  0.0122, -0.0464,  0.0411,  0.0145, -0.0025,  0.0363,  0.0413,\n",
      "        -0.0196, -0.0673,  0.0744, -0.0312,  0.0339,  0.0042,  0.0221,  0.0854,\n",
      "         0.0677,  0.0834, -0.0413, -0.0267,  0.0088, -0.0249,  0.0829,  0.0733,\n",
      "        -0.0033, -0.0611, -0.0506, -0.0855, -0.0126,  0.0610,  0.0230, -0.0096,\n",
      "         0.0777, -0.0836,  0.0688,  0.0538,  0.0755, -0.0494, -0.0738,  0.0581,\n",
      "         0.0546, -0.0504,  0.0850,  0.0095, -0.0486, -0.0734, -0.0669,  0.0376,\n",
      "         0.0648, -0.0821,  0.0091,  0.0688, -0.0825,  0.0886, -0.0352, -0.0400,\n",
      "        -0.0766, -0.0790, -0.0027, -0.0300], requires_grad=True), Parameter containing:\n",
      "tensor([[ 2.1900e-02,  8.8448e-02, -6.8501e-02, -2.5936e-02, -3.5885e-02,\n",
      "          2.3718e-02,  1.7417e-02,  9.9576e-02, -7.5298e-02, -6.0861e-02,\n",
      "         -2.7776e-02,  6.1456e-02, -2.7798e-02,  3.2754e-02,  3.3321e-03,\n",
      "         -7.1104e-02, -7.6238e-02,  5.7941e-02,  1.0733e-01,  8.0264e-02,\n",
      "         -2.6617e-02, -2.3997e-02,  9.5309e-02,  5.3330e-02,  7.5678e-02,\n",
      "         -6.2003e-02,  1.0081e-01, -4.2047e-02, -2.9566e-02, -1.6077e-02,\n",
      "         -5.1496e-02, -1.0342e-01,  6.7622e-02,  5.0823e-02,  2.2687e-02,\n",
      "         -1.0333e-01, -9.2652e-02, -2.8459e-02,  3.5247e-02,  3.1850e-02,\n",
      "          7.6747e-02, -7.8083e-02,  9.7350e-02,  3.9043e-02,  3.1708e-02,\n",
      "          3.6237e-02,  9.9831e-02, -7.8045e-02, -8.2724e-02,  9.4890e-02,\n",
      "          1.0490e-01,  1.6870e-03,  5.8719e-03,  2.1527e-02, -8.3637e-02,\n",
      "         -6.6292e-02, -9.5160e-02, -1.5518e-02,  5.4664e-02, -6.2797e-02,\n",
      "         -1.0302e-02, -8.9928e-02,  2.8775e-02, -4.8090e-03,  4.2586e-02,\n",
      "          6.6786e-02, -9.0165e-02,  9.5455e-02, -9.5918e-02, -7.1205e-03,\n",
      "         -4.6670e-02,  4.6740e-02, -3.3583e-02,  9.1957e-02, -1.6323e-02,\n",
      "          1.6223e-02,  7.2216e-02,  6.4666e-03, -3.5559e-02,  1.0562e-01,\n",
      "         -6.7798e-02, -1.5287e-02, -8.8884e-02, -6.0534e-03],\n",
      "        [-8.7601e-02, -9.1932e-02, -6.2826e-03,  7.7776e-02,  1.0388e-01,\n",
      "         -8.7690e-04, -5.4005e-02, -5.6088e-03, -9.4448e-02, -4.4434e-02,\n",
      "         -4.6108e-02,  9.9408e-02, -6.1289e-02, -8.1935e-02, -2.0804e-02,\n",
      "         -5.7641e-02, -3.4999e-02, -7.2493e-02,  3.4097e-02, -2.0029e-02,\n",
      "          3.6818e-02,  4.0212e-02, -1.0502e-01,  1.1785e-02, -7.0367e-02,\n",
      "         -1.1444e-02,  6.0027e-02,  3.1461e-02, -3.8659e-02,  4.6489e-02,\n",
      "          7.8217e-02, -5.3833e-02,  2.7321e-02,  7.3567e-02,  7.4359e-02,\n",
      "         -8.2733e-02,  2.7761e-02, -7.7402e-02, -8.9251e-02,  9.5657e-02,\n",
      "          1.9317e-02,  4.7945e-03, -4.9076e-02,  2.7924e-02,  2.6251e-02,\n",
      "          6.3881e-02,  9.3258e-02, -1.8407e-02, -3.5154e-02, -1.0819e-01,\n",
      "         -9.6273e-03, -7.7057e-02, -1.5228e-02, -6.2345e-02, -3.5146e-02,\n",
      "          2.9629e-02, -2.3083e-02,  1.8971e-02,  1.9123e-02, -7.7636e-02,\n",
      "          7.4457e-02,  8.0798e-02,  3.3103e-02, -4.3228e-02, -7.6598e-02,\n",
      "          6.0861e-02,  9.7907e-02, -7.8421e-02, -5.0865e-02,  5.6830e-02,\n",
      "         -2.2079e-02,  1.0322e-01, -3.5814e-03,  7.7943e-02,  6.0966e-02,\n",
      "          6.5745e-02,  8.4791e-02,  3.5916e-02, -2.6899e-02,  6.8142e-02,\n",
      "          2.7115e-02, -8.8233e-03,  7.7656e-02,  6.1434e-02],\n",
      "        [-4.1769e-02,  1.0638e-01, -7.4595e-02, -3.6543e-04,  9.3290e-02,\n",
      "          6.6409e-02,  1.2461e-03, -1.9615e-02,  7.0589e-02, -6.9038e-02,\n",
      "          5.9938e-02, -2.3751e-02,  3.1369e-02, -9.7396e-03,  3.8067e-02,\n",
      "          3.1197e-02, -8.9796e-02, -5.5587e-02,  2.1825e-02, -7.8867e-02,\n",
      "          1.0091e-02,  6.6178e-02, -7.2349e-02,  2.1801e-02,  6.1206e-02,\n",
      "         -2.1636e-02,  4.6406e-02,  2.1523e-02,  9.0422e-02, -5.5095e-02,\n",
      "          4.9868e-03, -7.6517e-02,  5.4318e-02, -1.3148e-02, -1.2355e-02,\n",
      "          4.5155e-02,  4.4746e-02, -3.9164e-02,  4.8646e-02, -6.7546e-02,\n",
      "          9.1247e-02,  9.8324e-02,  1.0707e-01,  7.4283e-02, -8.2954e-02,\n",
      "          8.7964e-02,  2.8948e-02, -4.8919e-02, -3.0703e-02,  5.0211e-02,\n",
      "          5.4274e-02, -1.0476e-01,  1.0447e-01,  1.0552e-01,  3.6035e-02,\n",
      "         -4.5306e-02, -3.7736e-04, -5.3597e-02, -9.0784e-03, -8.5778e-02,\n",
      "         -5.2037e-02,  7.2345e-02, -7.8405e-03, -9.5832e-02, -7.4604e-02,\n",
      "         -5.0054e-02, -6.2084e-02, -2.7825e-02, -4.9309e-02,  1.0316e-01,\n",
      "         -7.3359e-02,  6.2558e-02,  2.3690e-02,  9.6023e-02, -8.9447e-02,\n",
      "          6.4304e-02, -2.9396e-02,  2.8433e-02, -3.1884e-02, -1.8609e-02,\n",
      "          9.5550e-02, -8.4934e-04,  2.0785e-02,  3.0059e-02],\n",
      "        [ 7.9169e-02, -3.3520e-02,  1.5017e-02, -2.9098e-03, -9.1172e-02,\n",
      "          7.6587e-03,  8.0106e-02,  4.1731e-02, -9.4852e-02, -7.3736e-02,\n",
      "         -2.2039e-02, -1.0469e-01, -9.2539e-02, -7.7927e-02, -8.1060e-02,\n",
      "          9.0727e-02, -8.7797e-02, -7.0244e-02,  1.5756e-02,  1.0899e-01,\n",
      "         -7.9921e-02, -2.2113e-02,  3.0389e-02,  8.7669e-02,  3.7040e-02,\n",
      "         -3.6701e-02,  9.2669e-02, -2.2007e-02, -7.0133e-02,  6.7998e-02,\n",
      "          5.4672e-02, -6.3263e-02, -1.2805e-02,  4.8531e-02,  1.0072e-01,\n",
      "          9.9068e-03,  9.5664e-02,  7.0184e-02, -8.7432e-02,  2.2716e-02,\n",
      "          1.0273e-01,  8.1798e-02, -1.3570e-02,  2.9674e-02, -8.5545e-02,\n",
      "         -7.1646e-02,  4.5400e-02, -8.9088e-02,  3.0896e-02, -1.2388e-03,\n",
      "          9.0024e-03,  1.3866e-03,  1.5497e-02,  7.5443e-02,  6.5171e-02,\n",
      "         -5.6145e-02,  8.8724e-02,  1.2177e-02, -5.3417e-02,  9.7297e-02,\n",
      "          8.8668e-02, -8.0224e-03,  7.7659e-02,  3.6933e-02, -3.2490e-02,\n",
      "          6.0828e-02, -8.6173e-02, -1.0765e-01,  2.6836e-02,  1.0064e-01,\n",
      "         -2.4417e-02,  8.1718e-02,  2.3853e-02, -7.0911e-02,  7.9483e-02,\n",
      "          7.4910e-03, -8.7897e-02, -1.0849e-01, -2.4388e-02, -6.2492e-03,\n",
      "          5.5997e-02, -1.0131e-01, -1.0787e-01, -2.8591e-02],\n",
      "        [ 7.1111e-02, -1.0495e-01, -8.9332e-02, -3.1830e-02,  6.6064e-02,\n",
      "         -7.3889e-02, -3.6340e-02,  7.0610e-02, -1.6633e-02, -7.8221e-02,\n",
      "          3.8268e-02,  1.0409e-01, -3.3934e-02,  7.7751e-02,  4.5805e-02,\n",
      "         -9.8152e-02, -8.5620e-03,  1.0819e-01, -7.4324e-02, -1.3972e-02,\n",
      "          1.9421e-02, -9.0071e-02,  8.9345e-02,  2.5082e-02, -5.4976e-02,\n",
      "         -1.6258e-02, -6.8828e-02,  4.5526e-02, -7.6240e-02,  7.4196e-02,\n",
      "         -8.7267e-02,  7.4189e-02,  6.6025e-02, -9.0679e-02, -2.9027e-02,\n",
      "         -4.4058e-02, -9.4425e-02,  5.6471e-02, -2.5523e-04, -7.8955e-03,\n",
      "         -7.8351e-02, -8.3695e-02, -4.1433e-02,  2.0118e-02,  3.9974e-02,\n",
      "         -2.6822e-02, -1.0279e-01, -9.7789e-02,  8.4866e-02, -9.1986e-02,\n",
      "          1.1718e-02,  7.4540e-02,  5.3178e-02,  6.3881e-03,  3.9572e-02,\n",
      "         -1.9917e-03, -5.3272e-02,  1.0126e-01, -9.5164e-02,  5.0399e-02,\n",
      "         -1.6151e-02, -8.3851e-02,  6.0645e-02, -8.0912e-02, -8.5248e-02,\n",
      "         -8.7542e-02,  1.0280e-01,  7.6666e-02, -3.0001e-02,  2.8374e-02,\n",
      "         -2.8823e-02,  7.3604e-02, -1.4934e-02,  1.1231e-03, -7.8663e-02,\n",
      "         -8.2131e-02, -3.9795e-02,  2.0938e-02,  1.0724e-01,  1.0167e-01,\n",
      "         -9.8922e-02, -9.0131e-02, -6.4070e-02, -3.4515e-02],\n",
      "        [ 9.4259e-02,  7.2233e-02, -9.1941e-03,  3.3087e-02,  2.2544e-02,\n",
      "          4.0940e-04,  1.3265e-02,  1.5269e-02, -6.2932e-02, -7.0149e-02,\n",
      "         -6.1780e-02, -4.3347e-02,  7.1525e-02,  9.9530e-02,  9.8774e-02,\n",
      "         -3.6532e-02,  1.0015e-01, -1.6199e-02, -1.0255e-01, -2.0138e-02,\n",
      "          1.0213e-01, -5.2210e-03, -1.7553e-02,  7.9600e-02, -9.9587e-02,\n",
      "         -9.4035e-02, -8.8217e-02, -1.0899e-01,  8.7804e-02, -6.3337e-02,\n",
      "         -2.8702e-02,  7.2656e-02, -8.8398e-02, -9.5354e-02,  1.0633e-01,\n",
      "         -7.9540e-02,  5.0273e-03,  5.9376e-03, -1.9357e-05,  2.4077e-02,\n",
      "         -1.0088e-01,  5.3850e-02,  4.8306e-02, -7.4050e-03, -9.9723e-03,\n",
      "          2.6815e-02,  2.7158e-02,  1.7389e-02,  1.0844e-01,  6.8941e-02,\n",
      "          6.0461e-02, -8.1214e-02,  9.9842e-02,  6.0979e-02, -2.5679e-03,\n",
      "         -6.8283e-03,  9.5534e-02, -4.1390e-02,  7.8007e-03,  7.8326e-02,\n",
      "          9.9112e-02, -2.4624e-02,  4.5834e-04,  5.8651e-02, -4.5530e-02,\n",
      "         -2.8483e-02, -1.0046e-01, -1.0437e-01,  1.0609e-01, -1.7488e-02,\n",
      "         -1.0978e-02,  9.5183e-02,  2.7742e-02,  7.8732e-02, -9.8103e-02,\n",
      "         -7.7497e-02,  3.7315e-02, -9.6091e-02,  2.3533e-02, -7.8472e-02,\n",
      "         -9.7136e-02, -2.6536e-02, -5.6230e-02,  8.0909e-02],\n",
      "        [ 7.7726e-02, -5.6825e-02,  2.6235e-02,  5.3533e-02, -1.0010e-01,\n",
      "          8.5503e-03,  4.5674e-04, -8.2939e-02,  6.8539e-02, -4.9615e-02,\n",
      "          2.7988e-02, -9.1717e-02,  5.4249e-02,  1.9463e-02,  8.9433e-02,\n",
      "         -6.2381e-03, -6.4258e-02,  4.3186e-02,  5.1499e-02,  9.6477e-02,\n",
      "         -5.5177e-02,  8.2016e-02, -9.7260e-02,  7.4500e-02, -8.0677e-02,\n",
      "         -3.7660e-02, -2.1393e-03,  6.9286e-02,  4.0007e-02,  2.8969e-02,\n",
      "          3.9225e-02, -2.6304e-02,  1.5220e-02,  7.9957e-02,  3.2515e-02,\n",
      "          4.0026e-02,  8.9325e-02,  9.2133e-02, -3.8297e-02, -1.0097e-01,\n",
      "          1.7988e-02, -1.8715e-02,  7.4243e-02, -4.3659e-02,  5.9060e-02,\n",
      "         -9.7174e-02,  7.1860e-02, -9.5433e-02,  3.2409e-02, -4.5788e-03,\n",
      "         -2.5117e-03, -4.6527e-02, -2.4701e-03, -7.2218e-02,  5.9197e-02,\n",
      "          8.4173e-02,  2.7574e-02,  7.2293e-02, -2.3573e-02,  2.3870e-03,\n",
      "         -1.4756e-02, -9.7428e-02,  7.4738e-02, -2.4036e-03, -3.7487e-02,\n",
      "          5.8706e-02,  8.9643e-02,  9.2158e-02,  1.1457e-02, -7.2484e-02,\n",
      "         -7.4083e-03,  1.2380e-02,  5.1259e-02,  3.5178e-02, -5.6094e-02,\n",
      "         -6.0243e-02,  4.2021e-02, -1.2561e-02, -5.2976e-02,  8.5838e-02,\n",
      "         -4.6104e-02,  2.3065e-02,  7.1954e-02,  3.9113e-02],\n",
      "        [-3.8560e-02,  5.5254e-02, -4.1547e-02,  5.4024e-02,  6.1899e-02,\n",
      "          7.4006e-02, -7.0126e-02, -5.2010e-02, -9.7146e-02,  1.0261e-01,\n",
      "          6.9291e-02, -1.0516e-01,  4.0581e-03,  2.4133e-03, -4.8783e-04,\n",
      "          8.7390e-02,  1.5550e-03,  1.8078e-02, -8.8116e-02,  3.8874e-02,\n",
      "         -7.5076e-02, -3.9467e-03, -1.3212e-02,  6.8670e-02,  8.3914e-02,\n",
      "          8.4333e-02, -1.2294e-02,  6.2448e-02,  1.0728e-02, -3.4455e-02,\n",
      "          9.1428e-03,  1.0524e-01, -1.0908e-01, -1.4859e-02, -2.4749e-02,\n",
      "         -4.5892e-02,  4.8140e-02,  7.9156e-02,  9.4892e-02, -8.4866e-02,\n",
      "         -6.0995e-02,  7.3641e-02,  8.2822e-02, -6.5947e-02, -9.5226e-02,\n",
      "          6.1146e-02, -1.8534e-02, -8.9851e-02,  5.1092e-02,  2.1215e-02,\n",
      "          5.9664e-02, -4.9339e-02,  7.3969e-02,  1.0136e-01,  4.0015e-02,\n",
      "         -5.1609e-02,  2.6592e-02, -4.7084e-02, -7.1683e-03,  6.3909e-02,\n",
      "          1.1168e-02,  7.1938e-02, -9.4971e-02, -9.0109e-02, -8.1710e-02,\n",
      "          9.4598e-02, -2.4534e-03, -4.3084e-02,  1.2943e-02, -3.4452e-03,\n",
      "          7.7605e-02, -3.4814e-04, -5.6017e-02,  6.9300e-03,  6.6323e-02,\n",
      "         -4.8754e-02, -1.1018e-02, -9.2593e-02, -1.0881e-01,  8.8515e-04,\n",
      "         -7.9139e-03,  5.7481e-02,  1.0398e-01,  5.2360e-02],\n",
      "        [-1.0286e-01, -9.6086e-02,  8.5115e-02, -6.2443e-02, -6.9402e-02,\n",
      "          1.0459e-01,  9.1651e-02,  7.4185e-02,  9.5403e-02, -3.4484e-02,\n",
      "         -8.4281e-02,  5.2849e-03,  2.0574e-02, -7.6239e-02, -5.7349e-02,\n",
      "         -1.0264e-01,  8.7136e-02, -3.0393e-02, -7.6976e-02,  2.3357e-02,\n",
      "          3.5398e-03,  7.2615e-02,  2.9783e-02, -2.0021e-02,  1.5165e-02,\n",
      "          1.0525e-01, -1.0597e-01,  7.4997e-03,  1.1486e-03, -7.8990e-02,\n",
      "          1.0889e-01, -6.2609e-02, -5.4314e-02,  2.0899e-02, -3.2403e-02,\n",
      "          2.1305e-02, -7.1274e-02, -7.6922e-02,  4.3394e-02, -6.3257e-02,\n",
      "         -2.5377e-02,  2.2075e-02, -1.0082e-01,  6.0240e-02,  2.2490e-02,\n",
      "         -8.6192e-02,  9.6110e-03, -1.0823e-01, -2.9345e-02, -3.9644e-02,\n",
      "          1.4727e-02,  5.3596e-03, -1.5729e-04,  4.7152e-02, -2.3624e-02,\n",
      "         -7.1032e-02, -6.8327e-02, -6.3101e-02,  4.3043e-02,  3.8498e-02,\n",
      "          3.1349e-02, -4.3153e-02,  2.3844e-04, -6.1057e-02, -4.9190e-02,\n",
      "          9.7316e-02,  4.2122e-02,  5.2441e-02,  4.4858e-02,  8.8769e-02,\n",
      "          6.0022e-02,  4.2731e-02, -2.7023e-02, -2.8869e-02, -9.3753e-02,\n",
      "          5.9828e-02, -4.5883e-02,  9.5386e-02, -5.8008e-02,  9.3329e-02,\n",
      "          8.0322e-02, -9.2634e-02,  6.6196e-02,  8.4737e-03],\n",
      "        [ 6.2548e-02, -6.9073e-02,  1.0496e-01,  1.8073e-02,  8.8258e-02,\n",
      "         -1.0697e-01,  1.0731e-01, -7.0584e-02, -4.7700e-02, -1.0753e-01,\n",
      "         -9.1687e-02, -4.1422e-02,  8.5783e-02, -6.5657e-03,  8.8179e-02,\n",
      "         -2.6464e-02,  8.9468e-02,  2.6162e-02, -1.6255e-02, -7.4441e-02,\n",
      "          3.7530e-02,  6.4822e-02, -2.6944e-02, -4.9697e-02,  5.3194e-02,\n",
      "         -4.1160e-02, -4.8304e-02, -4.8232e-02,  6.9399e-03,  2.7817e-02,\n",
      "          7.0849e-02, -7.3019e-02,  7.9105e-02, -7.6091e-02, -5.2864e-02,\n",
      "          1.0474e-01,  6.8619e-02,  8.2837e-03, -1.0045e-01, -6.5337e-02,\n",
      "          8.5343e-03,  6.7327e-02, -2.4690e-02,  1.8631e-02, -5.9171e-02,\n",
      "         -7.3573e-02, -7.2977e-02,  9.3071e-02,  1.0893e-01, -5.6603e-02,\n",
      "          1.9249e-02, -1.0355e-01, -9.4955e-02,  3.7179e-02, -9.1304e-02,\n",
      "          1.4809e-02,  2.0682e-02, -1.0500e-01,  6.9045e-02, -4.1759e-02,\n",
      "          1.0174e-01, -4.3315e-02,  7.4042e-02,  5.4324e-02,  9.2912e-02,\n",
      "          4.5936e-03,  1.0510e-01,  6.1686e-02, -1.5477e-02, -9.9158e-02,\n",
      "          2.0815e-04, -3.2772e-02, -1.4257e-02, -2.0696e-02, -1.9759e-03,\n",
      "          8.2923e-02, -5.8155e-02, -3.5856e-02,  3.5079e-02,  2.0131e-02,\n",
      "         -8.1456e-02,  4.0945e-02, -4.7388e-02,  5.7627e-03]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0024, -0.0010,  0.0318,  0.0677, -0.0283, -0.0682,  0.0615,  0.0144,\n",
      "         0.0962, -0.1084], requires_grad=True)]\n",
      "10\n",
      "torch.Size([12, 3, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(params)\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1's .weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0392, -0.0588, -0.1414,  0.0110, -0.0025, -0.0452, -0.0219, -0.0486,\n",
      "         -0.0481, -0.0667]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Loss with MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7220, grad_fn=<MseLossBackward0>)\n",
      "<MseLossBackward0 object at 0x106c9d930>\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)  # a dummy target, for example\n",
    "target = target.view(1, -1)  # make it the same shape as output\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)\n",
    "print(loss.grad_fn)  # MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward0 object at 0x293496350>\n",
      "<AddmmBackward0 object at 0x293496500>\n",
      "<AccumulateGrad object at 0x293496350>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)  # MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backpropagate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "None\n",
      "conv1.bias.grad after backward\n",
      "tensor([-1.0127e-02, -4.1697e-03, -5.2998e-03, -1.1979e-03,  3.5369e-06,\n",
      "        -6.0802e-03])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the weights using SGD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight = weight - learning_rate * gradient\n",
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.3687e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.3687e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.1254e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.1254e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.0488e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.0488e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.1164e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.1164e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.3086e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.3086e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.6087e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.6087e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.0040e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.0040e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.4786e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.4786e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.0222e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.0222e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.6263e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.6263e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.2832e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.2832e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.9852e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.9852e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.7265e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.7265e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.5019e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.5019e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3069e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3069e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1380e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1380e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.9070e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.9070e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.6261e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.6261e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.5130e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.5130e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.5450e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.5450e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.7031e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.7031e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.9708e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.9708e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.3335e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.3335e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.7795e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.7795e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2980e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2980e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.8778e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.8778e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.5114e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.5114e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.1921e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.1921e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.9138e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.9138e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.6712e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.6712e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4597e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4597e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2753e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2753e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1145e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1145e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.7442e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.7442e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.5206e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.5206e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.4503e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.4503e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.5168e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.5168e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.7018e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.7018e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.9893e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.9893e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.3673e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.3673e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.8236e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.8236e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.3477e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.3477e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.9322e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.9322e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.5692e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.5692e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.2510e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.2510e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.9728e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.9728e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.7289e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.7289e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.5159e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.5159e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3296e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3296e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1658e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1658e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0228e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0228e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.9722e-08, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.9722e-08, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.8776e-08, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.8776e-08, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.9149e-08, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.9149e-08, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.0713e-08, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.0713e-08, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.3299e-08, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.3299e-08, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.6816e-08, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.6816e-08, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.1105e-08, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.1105e-08, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.6126e-08, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.6126e-08, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1747e-08, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1747e-08, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.7890e-08, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.7890e-08, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.4520e-08, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.4520e-08, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.1553e-08, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.1553e-08, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.8956e-08, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.8956e-08, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.6665e-08, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.6665e-08, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4661e-08, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4661e-08, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2898e-08, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2898e-08, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1348e-08, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1348e-08, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.9860e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.9860e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.7915e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.7915e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.7424e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.7424e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.8120e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.8120e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.9992e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.9992e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.2826e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.2826e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.6563e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.6563e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.0957e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.0957e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.6117e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.6117e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1799e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1799e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.8039e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.8039e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.4695e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.4695e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.1765e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.1765e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.9202e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.9202e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.6932e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.6932e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4934e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4934e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3155e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3155e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1624e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1624e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0260e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0260e-09, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.0661e-10, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.0661e-10, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.9934e-10, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.9934e-10, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.0507e-10, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.0507e-10, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.2225e-10, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.2225e-10, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.5069e-10, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.5069e-10, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.8537e-10, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.8537e-10, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.2913e-10, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.2913e-10, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.7892e-10, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.7892e-10, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.3531e-10, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.3531e-10, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.9540e-10, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.9540e-10, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.6287e-10, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.6287e-10, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.3018e-10, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.3018e-10, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.0459e-10, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.0459e-10, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.8101e-10, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.8101e-10, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.6116e-10, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.6116e-10, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4264e-10, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4264e-10, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2632e-10, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2632e-10, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1124e-10, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1124e-10, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.8559e-11, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.8559e-11, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# in your training loop:\n",
    "while loss.item() > 1E-10:\n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    output = net(input)\n",
    "    criterion = nn.MSELoss()\n",
    "    loss = criterion(output, target)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()    # Does the update\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training an image classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:30<00:00, 5557025.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog   deer  ship  horse\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.115\n",
      "[1,  4000] loss: 1.731\n",
      "[1,  6000] loss: 1.565\n",
      "[1,  8000] loss: 1.484\n",
      "[1, 10000] loss: 1.407\n",
      "[1, 12000] loss: 1.390\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:  cat   ship  ship  plane\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  dog   car   car   ship \n"
     ]
    }
   ],
   "source": [
    "outputs = net(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 53 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks way better than chance, which is 10% accuracy (randomly picking a class out of 10 classes). Seems like the network learnt something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: plane is 47.9 %\n",
      "Accuracy for class: car   is 78.5 %\n",
      "Accuracy for class: bird  is 38.8 %\n",
      "Accuracy for class: cat   is 14.7 %\n",
      "Accuracy for class: deer  is 44.6 %\n",
      "Accuracy for class: dog   is 47.9 %\n",
      "Accuracy for class: frog  is 78.2 %\n",
      "Accuracy for class: horse is 55.4 %\n",
      "Accuracy for class: ship  is 57.2 %\n",
      "Accuracy for class: truck is 66.3 %\n"
     ]
    }
   ],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n",
      "[1,  2000] loss: 1.238\n",
      "[1,  4000] loss: 1.259\n",
      "[1,  6000] loss: 1.266\n",
      "[1,  8000] loss: 1.255\n",
      "[1, 10000] loss: 1.247\n",
      "[1, 12000] loss: 1.249\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('mps')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)\n",
    "net.to(device)\n",
    "inputs, labels = data[0].to(device), data[1].to(device)\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        #inputs, labels = data\n",
    "        #move to gpu\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
